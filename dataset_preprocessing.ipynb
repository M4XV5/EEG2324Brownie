{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### Removing Bad Participants from the Analysis.\n",
    "1. We are removing the first **n** trials for every cue in every casino. This ensures that the participants are able to learn the pattern of every slot as we want to measure how the RewP changes in different average task values. For that the participants have to learn first what the average task value is of every slot.\n",
    "2. We are removing participants that do not manage to get **threshold** of the learnable trials correct, i.e. choosing the lever with the higher win probability. Thus, we assume that participants did not truly care about the reward. As we want to measure the RewP in different averaging task values, this requires participants to truly want to win corresponding to dopamine release on a win."
   ]
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-02T15:36:17.519440300Z",
     "start_time": "2024-02-02T15:36:11.840601400Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Behavioral file for code does not exist.\n",
      "sub-27 does meet the threshold and should be included in the analysis.\n",
      "sub-28 does meet the threshold and should be included in the analysis.\n",
      "sub-29 does meet the threshold and should be included in the analysis.\n",
      "sub-30 does meet the threshold and should be included in the analysis.\n",
      "sub-31 does meet the threshold and should be included in the analysis.\n",
      "sub-32 does meet the threshold and should be included in the analysis.\n",
      "sub-33 does meet the threshold and should be included in the analysis.\n",
      "sub-34 does meet the threshold and should be included in the analysis.\n",
      "sub-35 does meet the threshold and should be included in the analysis.\n",
      "sub-36 does meet the threshold and should be included in the analysis.\n",
      "sub-37 does meet the threshold and should be included in the analysis.\n",
      "sub-38 does meet the threshold and should be included in the analysis.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from utils import copyanything\n",
    "\n",
    "# HYPERPARAMS\n",
    "n = 4\n",
    "threshold = 0.7\n",
    "\n",
    "\n",
    "subjects_dir = 'Dataset/ds004147'\n",
    "copyanything(subjects_dir, f\"{subjects_dir}-filtered\")\n",
    "subject_dir = f\"{subjects_dir}-filtered\"\n",
    "subject_dirs = [d for d in os.listdir(subjects_dir) if os.path.isdir(os.path.join(subjects_dir, d))]\n",
    "removed_trial_dict = {}\n",
    "for subject_dir in subject_dirs:\n",
    "    beh_file_path_tsv = os.path.join(subjects_dir, subject_dir, 'beh', f'{subject_dir}_task-casinos_beh.tsv')\n",
    "    if os.path.exists(beh_file_path_tsv):\n",
    "        df = pd.read_csv(beh_file_path_tsv, sep='\\t')\n",
    "        # remove the first four trials for every cue and block\n",
    "        filtered_df = df.groupby(['block', 'cue']).apply(lambda x: x.iloc[4:]).reset_index(drop=True)\n",
    "        filtered_df = filtered_df[filtered_df['invalid'] != 1]\n",
    "        removed_trials = df.groupby(['block', 'cue']).apply(lambda x: x.iloc[:4]).reset_index(drop=True)\n",
    "        removed_trials[\"trial\"] = removed_trials[\"trial\"] + (removed_trials[\"block\"] - 1) * 144\n",
    "        removed_trial_dict[subject_dir] = removed_trials\n",
    "        df_sorted = filtered_df.sort_values(by=['block', 'trial'])\n",
    "        # aggregate learnable trials and mark participants that did not meet the threshold\n",
    "        learnable_trials = filtered_df[filtered_df['prob'] == 80]\n",
    "        correct_choices = learnable_trials['outcome'] == learnable_trials['optimal']\n",
    "        success_rate = correct_choices.mean()\n",
    "        threshold_met = success_rate >= threshold\n",
    "        if threshold_met:\n",
    "            print(f\"{subject_dir} does meet the threshold and should be included in the analysis.\")\n",
    "            df_sorted.to_csv(os.path.join(subjects_dir, subject_dir, 'beh', f'{subject_dir}_task-casinos_beh.tsv'), sep='\\t', index=False)\n",
    "        else:\n",
    "            print(f\"{subject_dir} does  not meet the threshold and should be not included in the analysis.\")\n",
    "            df_sorted.to_csv(os.path.join(subjects_dir, subject_dir, 'beh', f'{subject_dir}_REJECT_task-casinos_beh.tsv'), sep='\\t', index=False)\n",
    "    else:\n",
    "        print(f'Behavioral directory for {subject_dir} does not exist.')"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "\n",
    "After choosing n=4 and threshold=0.7, no participants went under the threshold. The authors noted that some were excluded, so we believe that these participants where from the other test site."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Filter the first n=4 trials for every slot in every casino for every participant\n",
    "During the removal of bad participants, we also returned a filtered beh.tsv without the first n=4 trials. We do this for the eeg.vmrk and events.tsv files, respectively. Moreover, invalid trials are also removed, as the data is unnecessary.\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "eeg.vmrk file for code does not exist.\n",
      "Subject: sub-27 had 0 invalid trials!\n",
      "Subject: sub-28 had 0 invalid trials!\n",
      "Subject: sub-29 had 0 invalid trials!\n",
      "Subject: sub-30 had 0 invalid trials!\n",
      "Subject: sub-31 had 0 invalid trials!\n",
      "Subject: sub-32 had 0 invalid trials!\n",
      "Subject: sub-33 had 0 invalid trials!\n",
      "Subject: sub-34 had 0 invalid trials!\n",
      "Subject: sub-35 had 0 invalid trials!\n",
      "Subject: sub-36 had 0 invalid trials!\n",
      "Subject: sub-37 had 0 invalid trials!\n",
      "Subject: sub-38 had 0 invalid trials!\n"
     ]
    }
   ],
   "source": [
    "from mne_bids import (BIDSPath,read_raw_bids)\n",
    "import mne\n",
    "import tqdm\n",
    "\n",
    "# path where to save the datasets.\n",
    "bids_root = subjects_dir\n",
    "\n",
    "for subject_dir in subject_dirs:\n",
    "    eeg_vmrk_path = os.path.join(subjects_dir, subject_dir, 'eeg', f'{subject_dir}_task-casinos_eeg.vmrk')\n",
    "    eee_events_tsv_path = os.path.join(subjects_dir, subject_dir, 'eeg', f'{subject_dir}_task-casinos_events.tsv')\n",
    "    eeg_events_json_path = os.path.join(subjects_dir, subject_dir, 'eeg', f'{subject_dir}_task-casinos_events.json')\n",
    "    if os.path.exists(eeg_vmrk_path):\n",
    "        with open(eeg_vmrk_path, 'r') as file:\n",
    "            lines = file.readlines()\n",
    "        start_index = 13  \n",
    "        groups = []\n",
    "        current_group = []\n",
    "        for i, line in enumerate(lines[start_index:], start=start_index):\n",
    "            if any(stim in line for stim in ['S  1', 'S 11', 'S 21', 'S 31']):\n",
    "                if current_group:\n",
    "                    groups.append(current_group)\n",
    "                    current_group = []\n",
    "            current_group.append(i)\n",
    "        if current_group:\n",
    "            groups.append(current_group)\n",
    "        groups = [(idx+1, element) for idx, element in enumerate(groups)]\n",
    "        invalid = [(idx, element) for idx, element in groups if len(element) != 5]  # filter invalid trials, i.e. sublist != 5\n",
    "        print(f\"Subject: {subject_dir} had {len(invalid)} invalid trials!\")\n",
    "        # filter the 4 trials for every slot in every casino\n",
    "        first_four = [(idx, item) for idx, item in groups if idx in removed_trial_dict[subject_dir][\"trial\"].values]\n",
    "        first_four_invalid= [item for item in first_four if len(item[1]) != 5]\n",
    "        # remove duplicate in invalid (invalid trials could be in the first four trials of a slot)\n",
    "        invalid = [item for item in invalid if item not in first_four_invalid]\n",
    "        first_four.extend(invalid)\n",
    "        # convert to list of lines to remove\n",
    "        first_four = [element[1] for element in first_four]\n",
    "        lines_to_remove = []\n",
    "        [lines_to_remove.extend(element) for element in first_four]\n",
    "        filtered_lines = [line for idx, line in enumerate(lines) if idx not in lines_to_remove]\n",
    "        \n",
    "        # create filtered vrmk file\n",
    "        #print(f\"Adapting eeg.vmrk and events.tsv file for {subject_dir}\")\n",
    "        with open(os.path.join(subjects_dir, subject_dir, 'eeg', f'{subject_dir}_task-casinos_eeg.vmrk'), \"w\") as file:\n",
    "            # Write each item to the file\n",
    "            for item in filtered_lines:\n",
    "                file.write(item)\n",
    "        \n",
    "        \n",
    "        # do the same for events.tsv file\n",
    "        with open(eee_events_tsv_path, 'r') as file:\n",
    "            lines = file.readlines()\n",
    "        lines_to_remove = [idx - 10 for idx in lines_to_remove]\n",
    "        filtered_lines = [line for idx, line in enumerate(lines) if idx not in lines_to_remove]\n",
    "        with open(os.path.join(subjects_dir, subject_dir, 'eeg', f'{subject_dir}_task-casinos_events.tsv'), \"w\") as file:\n",
    "            # Write each item to the file\n",
    "            for item in filtered_lines:\n",
    "                file.write(item)\n",
    "    else:\n",
    "        print(f'eeg.vmrk file for {subject_dir} does not exist.')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-02T15:36:17.742060100Z",
     "start_time": "2024-02-02T15:36:17.526923200Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Cue-related Stimuli choice\n",
    "Now we are loading the dataset and first analyze the different cue stimuli (e.g. high-task and low-cue, medium-task and high-cue etc.). Usually, we would have to take the stimuli which is responsible for the onset of the cue, but due to missing cue and task combinations in the sub-X_task-casinos_events.json, we instead take the stimuli which corresponds to the beep, i.e. S3, S13, S23 and S33. "
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "<img alt=\"image\" src=\"Paper/trial_pipeline.jpg\" width=\"1500\"/>\n",
    "\n",
    "To make our workaround of using beep stimuli work, we will set the Epoch range to -1200ms and -600ms, which matches with the range the authors have used. As can be seen from the trial pipeline (the step after the fixation cross equates to the cue onset), setting the time range like this would correspond to -200ms and 600ms for the cue onset stimulus."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
